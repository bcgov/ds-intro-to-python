---
title: Exploring Data Structures
teaching: 45
author: Stuart Hemerling
exercises: 4
objectives:
  - to be able to understand and use some basic tools to manipulate dataframes
  - to be able to understand and use tools to create a subset of data based on logical filtering
  - to reinforce use of basic summarizing methods with the data
keypoints: null
jupyter: python3
---

## Exploring and Understanding Data

Getting a high level summary of the data is important but data is particularly valuable when refined. Your analysis will start to come alive when we start to do some slicing and dicing and grouping of data or even creating additional variables. In an Excel world, this is like when you use filter options for columns, or create pivot tables, or when you create a formula in a new column to create a new variable. In data science parlance, this is the kind of thing that is referred to as `data wrangling` - getting the (already cleaned) data you want in the form you want it in. 

In the world of python, this usually means working with a library or package you have already been introduced to called pandas. It let's you do so much!

The first dataset we'll look at is one that looks at data for countries around the world and shows population levels as well as gdp per capita over a number of years. It is a great data set to look at. 

## 3.1.1. Getting the data and an overview

```{python}
#| output: false
import pandas as pd
url = "https://raw.githubusercontent.com/bcgov/ds-intro-to-python/main/data/gapfinder.csv"
df = pd.read_csv(url)
```

It's usually a good idea right away to take a quick look at the data to make sure what we have read in makes sense. So let's do that using some pandas methods that we covered earlier.

:::{.callout-tip}
## Reminder: Naming variables!
When you create a variable or object, you can name it pretty much whatever you want. But it is a best practice to name it something intuitive but not overly verbose. Also remember to not leave spaces in your names, and to always be consistent in the naming conventions you use (e.g. camelCase, underscore_case, etc.)


:::

```{python}
df.info()
```

So this data is looking good so far. We can see that we have created a pandas dataframe within our python environment. There are 1704 rows of data and 6 columns or variables. You can see there are only non-null values... so happily there is no missing data to worry about.

```{python}
df.head(2)
```

The `.head()` method let's us look at actual data like we would likely do in Excel. This dataset has some high level country metrics about population and the economy going back to 1952. 

### Selecting columns (variables)

In the "real world" of data its not uncommon to see hundreds or thousands of columns, so knowing how to pare down our dataset so it is not overly bloated is important. Our dataset is just 6 columns wide, so not too big, but let's go ahead and narrow it down anyway.  

Let's create an object (in this case a dataframe) called "narrow_df" and then specify the names of columns that we want to have in our slimmed down dataset. We are primarily interested in population, but we want to have year, country, and continent in there too. After we create it let's take a look at the new dataframe:

```{python}
narrow_df = df[['country', 'year', 'pop', 'continent']]
narrow_df.head(2)
```

So now we have a more manageable dataset to work with called narrow_df. The original dataframe df is still there, and still the same size as before it we want to have a look though. 

:::{.callout-tip}
## Reminder on Assignment!
When you create a variable or dataframe in python, to the left of the `=` sign you always put the name of the thing you want to make or modify. To the right, that's where you put the contents of what it is you want to create. It may feel counterintuitive! Especially if you are using the same variable or dataframe identifier on both sides of the equals sign.
:::

:::{.callout-warning icon="false"}

## Challenge 1



Let's say you just want to narrow down the dataset to include just the country and the GDP per capita. How would you do it? Don't forget to run your code so it also shows a view of the result so you can confirm the code worked as you wanted it to. 

:::



:::{.callout-note icon="false" collapse="true"}

### Solution to Challenge 1

First you would like to create a new object to hold this narrowed down version of the dataset, then just use some method like `.head()` to see some of the resulting data. 

```{python}
challenge1_df = df[['country', 'gdpPercap']]
challenge1_df.head(2)
```

:::

### Selecting Rows

Of course, in data analysis we are usually interested in looking at just some of rows of data, not all of it all the time. So when we want to look at just selected rows (i.e. values within a given column) there is a handy pandas function called `.query()` that we can leverage. It helps us with selecting the rows we want. 

We set up an expression in pandas  with `.query()` and it will evaluate it for us. For example, imagine we want to find just the rows where the year is 1972. Here's how we do that, using `==` instead of just `=`:

```{python}
filtered_df = df.query('year == 1972')
filtered_df.head(2)
```

We can even get more specific with string variables, looking for content by starting letter or letters.  For example, here's how we can look for specific countries: 

```{python}
filtered_df = df.query('country.str.startswith("C") & year == 1972')
filtered_df.head(3)
```

:::{.callout-warning icon="false"}

## Challenge 2



Your director has come to you and asked if you know what the life expectancy was is in Canada in 2007.  How would you use pandas code to get the data you need? And after having run the code, what's the answer? 

:::



:::{.callout-note icon="false" collapse="true"}

### Solution to Challenge 2

First you would like to create a new object to hold this narrowed down version of the dataset, then just use some method like `.print()` or `.head()` to see some of the resulting data. 

```{python}
challenge2_df = df.query('country.str.startswith("Canada") & year == 1972')
print(challenge2_df)
```

:::

:::{.callout-tip}
## .loc() and .iloc() to also filter rows! 
There is something else you should know about row selection. It is VERY common within python/pandas to see the `.loc()` and `.iloc()` methods to identify rows by index location. The index starts at 0 for the first row (yes, "0", and not "1")!  You can also use these methods. You may not ever need to use it, but it is good to know what it means when you come across it. 
:::

```{python}
x_df = df.loc[0:1]
print(x_df)
```

### Sorting rows

So now you've mastered how to select rows and columns you want, congratulations!

Instead of hunting and pecking for insights, one way to quickly make some sense of the data is to sort it - something you probably do in Excel all the time. 

Above, we have created a dataframe with just the one country in it and for all years above 1972. So now let's sort the data by year, and then see what can spot any insights. To do this, we use the `.sort_values()` method.

Let's go fetch and look at the filtered_df dataframe from above, and use this method to sort by year, going from more recent to less recent:

```{python}
filtered_df.sort_values('lifeExp', ascending=False)
#
```

Here we can read a few insights out of the data.

### Putting multiple methods together (chaining)

You can also put multiple methods in the same line of code, as long as you separate each of the elements. In pandas, this is called "method chaining",  as you are kind of creating a chain of actions to take place. 

```{python}
#| scrolled: true
filtered_df = df.query('country.str.startswith("Ca") & year == 2007').sort_values('year', ascending = False)
filtered_df.head(3)
```

:::{.callout-warning icon="false"}

## Challenge 3



Your director has come back to you and wondered about whether the life expectancy of people changed during the 1970s in Cambodia. Use what you know about selecting rows and sorting data to get the data you need to answer the question. 

:::



:::{.callout-note icon="false" collapse="true"}

### Solution to Challenge 3

Use the `query()` and `sort_values()` methods and chain them together. Looking at the data we see that in the 1970s there was a sharp decline in life expectancy in Cambodia. We also see, thankfully, that it has recovered strongly since then. 

```{python}
challenge3_df = df.query('country.str.startswith("Cambodia") & year < 2008').sort_values('year', ascending = False)
print(challenge3_df)
```

:::

### Creating new columns of data

Very often we have some data in our dataset that we want to transform to give us additional information.

In Excel this is something that is done all the time by creating a formula in a cell that refers to other columns and applies some sort of logic or mathematical expression to it. In pandas, one handy tool to use is the `.assign()` method. 

Imagine we want to know what the actual GDP is for a given country for a given year and not just the GDP per capita. Can we do this? Let's take a look. It's with the help of an additional special Python function called `lambda`. 

We create our own little function right inside of the code that allows us to create this column (or variable, or feature). The logic is:

(new_variable_name  = `lambda x: some expression involving x and math and/or other variables`)

The `.assign()` method looks at this expression and then returns the value it is asked to do. This is how it comes all together to give us actual GDP for each row in our dataframe:

```{python}
new_df = df.assign(gdp=lambda x: x['pop'] * x['gdpPercap'])
new_df = new_df.query('year == 2007').sort_values('gdp', ascending = False)
new_df.head(5)
```

So now we can see which countries had the biggest GDP in 2007. Notice that the gdp data is in scientific notation (i.e. the decimal number times x number of zeros), so it's a bit hard to read. If we wanted readers to consume that data we would go ahead and change the data type for it. But for current purposes we'll leave that alone.

### Joining datasets together

One of the most important tasks in data analysis is to be able to join multiple datasets together. There is a second file that we can get regarding country size in square kilometers.  Let's fetch that data and take a look. 

```{python}
url2 = "https://raw.githubusercontent.com/bcgov/ds-intro-to-python/main/data/countrysize.csv"
df2 = pd.read_csv(url2, encoding= 'unicode_escape')
df2.info()
df2.sample(2)
```

Ok, this new dataset looks like we expect - a list of countries alongside the land size in square kilometers. 

While pandas makes it possible to join two dataframes on their index, joining on a particular "key" column is also possible. Joining on a key column is likely more intuitive for those familiar with merging with vlookup in Excel or joining tables with SQL. So let's go ahead and join this based on the "country" column from the original dataset and "nation" from the second one. In database management language, we are going to to a left join (perhaps the most common type of join). 

:::{.callout-important}
In pandas, there are two methods we can use to bring these datasets together, namely the `.merge()` and the `.join()` function. Both can accomplish many of the same tasks and you likely will come across both. But it probably makes sense to keep it simple and get familiar with one of them first, then move on to the next one later.
:::

In the example below we will use the `.join()` function. We will think of "df" as being the original dataset on the left, and df2 as the other dataset that we want to merge data from. We use for both the variable 'country' as the key to join on. We use an inline `.set_index()` function in order to preserve a nice looking index column on the left of the dataframe, based on the index of df. 

```{python}
join_df = df.join(df2.set_index('nation'), on='country')
join_df.head(2)
```

Now you want to see all of the columns in this new dataset but just for the year 2007 and you want to see it organized by gdp per capita. 

:::{.callout-warning icon="false"}

### Challenge 4



Your director has come back, yet again, and wants to know what top five countries were in terms GDP per capita in 2007. 

:::



:::{.callout-note icon="false" collapse="true"}

### Solution to Challenge 4

Using the `.query()` method, you specfy that you want to return the values that are equivalent to the year of interest.  Then you can chain along the `.sort_values()` method 

```python
challenge4_df = join_df.query('year == 2007').sort_values('gdpPercap', ascending = False)
challenge4_df.head(5)
```

:::

```{python}
challenge4_df = join_df.query('year == 2007').sort_values('gdpPercap', ascending = False)
challenge4_df.head(5)
```

### Grouping 

Sometimes of course you would prefer to group rows together for the purpose of summarizing them somehow. With our current dataset, we would like to  summarize it so that we can see the breakdown of the metrics for each year by country in alphabetical order. 

We can accomplish this using the `.groupby()` method together with another mathematical function. 

```{python}
group_df = join_df.groupby(by=['year']).sum()
group_df.head(20)
```

In the example above we see the sum of each of the metrics for all of the numerical columns in the respective year. So we see that world population grew from about 2.5 billion people in 1952 to over 6.25 billion in 2007. Luckily, the total land area of the world hasn't shrunk with all those extra people! 

### Summary 

By now you should be able to select the rows and columns of data you want directly and generate some quick on the fly insights as you need to. The next section will look at some of the more sophisticated and elegant tools for understanding and presenting your data. But the building blocks you have just learned about are the meat and potatoes of data analysis in the python world. 

