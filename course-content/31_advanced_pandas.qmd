---
title: "Advanced Pandas"
teaching: 45
exercises: 10
questions:
- "Fill this in!"
objectives:
- "Fill this in too!"
keypoints:
- "Same verse!"
---

<center>
    <img src="images/advanced-pandas/advanced_pandas.jpeg" 
    width="60%" style="margin:auto"/>
    <p style="text-align: center">
        Advanced. Pandas.
    </p>
</center>

In this section we will go over some Pandas functionality that is slightly more involved than the prior sessions. We hope to cover, or at least provide reference for operations such as:

 * Conditional Column Assignment
 * Advanced grouping techniques
 * Rolling and cumulative functions
 * Reshaping our data
 * Iterating over a dataframe 

## Conditional Column Assignment

TBD (.where and .mask)

## Advanced Grouping

In our previous section on Pandas, we explored the basic tools we need to group our data by various columns, apply a host of statistical aggregation operations, and look at these outcomes. While incredibly powerful as is, these tools lack some functionality that you might wish to have. Some examples include:

 * Combining row level values and group level aggregations in a single command.
 * Filtering and subsetting a dataframe based on group values. 
 * Combining aggregations across different columns. 

In order to handle these operations, we need to introduce two new methods: `transform` and `apply`. 

:::{.callout-tip}
## Apply... again?

You might question whether `apply` is actually a new function, seeing as we have used it previously when creating new columns in a dataframe. In fact, the effect of `apply` within pandas is subtly different depending on how and where we apply it. The effect of `apply` is different when used on:

 * A dataframe as a whole - `dataframe.apply(...)`
 * A single series - `series.apply(...)`
 * A grouped dataframe object - `dataframe.groupby('column').apply(...)`

Make sure you keep track of what kind of apply you are using when doing your dataframe manipulations, as identical functions in different scenarios can lead to unusually different results! In this section, we are focusing on the **grouped dataframe objects**. 
:::

Both `transform` and `apply` can be used on a grouped dataframe object. This is the object that is created when we use the `.groupby()` method. Let's create a small dataset and see what this object looks like:
```{python}
import pandas as pd
from numpy.random import randn

df = pd.DataFrame(
    {
        'unit' : [
            'Blaster', 'Blaster', 'Blaster', 
            'Lightsaber', 'Lightsaber', 'Lightsaber', 'Lightsaber', 
            'Stick', 'Stick', 'Stick'
            ], 
        'cost' : [42, 60, 40, 900, 4000, 2000, 100, 10, 1, 5],
        'sale_price' : [50, 75, 42, 1000, 5000, 2000, 4242, 4, 2, 20]
    }
)

df
```

Here we have a column that looks categorical (`unit`), and a couple that look numerical (`cost` and `sale_price`). We are going to focus on grouping our data according to the categorical column, and see what we can do with the numerical columns. 

```{python}
grouped_df = df.groupby('unit')
grouped_df
```

Note that this object is no longer a dataframe, but some sort of `DataFrameGroupBy` object. By itself, it is not very useful, but we can use it to get all sorts of interesting information. Recall briefly how we used this earlier. Maybe we want the average buy and sell prices of each type of unit:

```{python}
grouped_df.mean().reset_index()
```

What if we wanted to know how much each particular unit contributed to it's groups overall sale? Or perhaps how much each group profited, on average? This is where `transform` and `apply` come in. Let's look at what each of these do.

### Transform

 * Used to apply a function to a dataframe that produces a new dataframe with the same shape as the original.
 * While an entire dataframe can be passed to transform, it only ever sees (operates on) a single column/series at a time. 
 * The function must either return a scalar value or a sequence that is the **same length** as the original dataframe. 
 * Useful for getting groups aggregations back into the original dataframe
 * Useful for filtering based on group values 


#### Ex. 1: Percent of Group
Let's see each this in action. We will use transform to determine how much each unit contributed to the total sales of its group. 

```{python}
pct_of_sales = (
    grouped_df
    .sale_price
    .transform(lambda series_: series_/series_.sum())
)
pct_of_sales
```

Notice here that we used the `lambda` function again, which allows us to define a function inline acting on a given argument (in this case, the argument is named `series_`). This let us allow the value of the series to be the sum of the series. Because we are acting on a *grouped* object, Pandas knows that the sum we wish to employ is that of the group, not the overall sum! This new object will be in the same order (have the same indexing) as our initial dataframe, and so we can add it back to the dataframe as an extra column if we wish. This works explicitly because the transform method is required to return a series of the same length as the original object, giving us exactly what we want! 

```{python}
df['percent_of_sales'] = pct_of_sales
df
```

#### Ex 2: Grouped Aggregate
Transform can be used exclusively with an aggregation function as well, but it will still return a value for every row of the initial dataset. This allows us to add grouped level values as columns to the data:

```{python}
df['average_unit_cost'] = grouped_df.cost.transform('mean')
df
```

#### Ex 3: Multiple Series
Instead of passing a single column to the transform method, we could also pass the entire dataframe (or some subset of the columns in the dataframe), and calculate values for each series:

```{python}
grouped_df.transform(lambda series_: (series_-series_.mean())/series_.std())
```

This has created two columns that have both had the same function applied. Note that if we wanted to merge these in with the original dataframe, we should be careful to rename the columns so that they do not overlap!

#### Ex 4: Filtering Original Dataframe
Another use case for transform is in filtering a dataframe. Maybe we want to zero in on those items where the sale price of the object was less than the average unit cost. Let's filter our dataframe to only those rows:

```{python}
condition = df.sale_price < grouped_df.cost.transform(lambda x: x.mean())
df[condition]
```


### Apply

 * Used to apply a function (aggregated or otherwise) across multiple columns
 * Implicitly passes all the columns of the dataframe *as* a dataframe to the function, allowing for column interactions
 * The function can return a scalar or a sequence of any length.

#### Ex 1. Aggregate over Multiple Columns
Let's try something with apply. What if we want to know the average overall profit of each group. We could produce a profit column, group up on the unit, and then calculate the mean. 

```{python}
df['profit'] = df.sale_price - df.cost
df.groupby('unit').profit.mean()
```

We could also do this using the apply function, applied to our grouped object:

```{python}
grouped_df.apply(lambda df_: (df_.sale_price - df_.cost).mean())
```

Again, we made use of that `lambda` function, this time applying it to a `df_` argument. You might notice that here I used a `df_` argument instead of `series_`: this is merely notation, and we could have used anything (`series_`, `df_`, `x`, `this_is_my_argument` would all work the same). However, we have used `df_` and `series_` so that we can remind ourselves exactly what type of object we are acting on. 

To see how transform differs from apply, let's try to do that exact same operation:

```{python}
#| error: true
grouped_df.transform(lambda _df: (_df.sale_price - _df.cost).mean())
```

This fails because the object being acted on inside transform is itself just a series object, not the entire dataframe! As such, it has no attribute for `sale_price` or `buy_price` like our original dataframe does. Instead, it acts on the `sale_price` series, then the `buy_price` series, and returns the results.

#### Ex 2. Mix Row and Aggregate Levels
While the first apply example returns a rolled up aggregated dataframe, we can also use apply to return the individual rows of the dataframe by mixing aggregation functions with row level functions. 

```{python}
grouped_df.apply(lambda df_: df_.sale_price - df_.cost.mean())
```

In this way we have to be careful: transform will **always** return a dataframe that is the same size as the original, while apply will return something that varies with the type of function we have utilized. 

#### Ex 3. Partial Aggregates
Apply lets us play some cool tricks as well. Suppose we only wanted to know about the two most expensive sales in each category. How could we filter to show this? We can use the `nlargest` (or smallest) method in conjunction with apply. `nlargest` does exactly what we might expect, returning the rows with the n largest values according to the provided column(s):

```{python}
df.nlargest(2, 'sale_price')
```

But if we mix this with apply and our grouping dataframe, we can get the largest for each group!

```{python}
grouped_df.apply(lambda df_: df_.nlargest(2, 'sale_price'))
```

Note that when apply produces some different sized aggregate than the original dataframe, it tacks on an extra index indicating what the grouper was. We do not always care about this, and can eliminate it in the initial creation of our grouped dataframe via the `group_keys` argument:

```{python}
(
    df
    .groupby('unit', group_keys=False)
    .apply(lambda df_: df_.nlargest(2, 'sale_price'))
)
```



#### Ex 4. Create Multiple Columns
We can use the dataframe behaviour of apply to create multiple additional columns all at once within an apply. Let's create a function that will act on each dataframe group, create new values, and return the dataframe.

```{python}
def create_multiple_columns(df_):
    df_['average_group_profit'] = (df_.sale_price - df_.cost).mean()
    df_['profit_relative_to_group'] = df_['profit']/df_['average_group_profit']
    return df_

grouped_df.apply(create_multiple_columns)
```

<br>
When done this way, we are explicitly returning the dataframe, regardless of if it was grouped or not. Even if all of the new columns are aggregates, this will still produce a non-aggregated output: 

```{python}
def create_multiple_aggregated_columns(df_):
    df_['average_group_profit'] = (df_.sale_price - df_.cost).mean()
    df_['average_sale_price'] = df_.sale_price.mean()
    return df_

grouped_df.apply(create_multiple_aggregated_columns)
```

## Rolling and Cumulative Functions 

TBD... (.rolling, .cumsum)

## Reshaping Data

TBD... (pivot, melt)

## Iterating Over a Dataframe

TBD... (.iterrows)












